import random
from collections import OrderedDict
from threading import Thread
from time import sleep

import spacy
from IPython.core.display import display, clear_output
from ipywidgets import widgets
from spacy.matcher import PhraseMatcher
from sqlalchemy import or_, delete

from conf.ConfigReader import ConfigReader
from db.ORMs import Document, Annotation
from gui.PreviousNextWidgets import PreviousNextHTML, PreviousNextWithOtherBranches
from gui.Workflow import Step, logMsg
from models.sampling.KeywordStratefiedSampler import KeywordStratefiedSampler


class ReviewRBInit(PreviousNextWithOtherBranches):
    """Start review samples with rule-based method in the backend.
    This is more efficient and practical when reviewed data are relatively small at the beginning."""

    description = "<h4>Review samples: </h4><p>These pre-annotations are generated by the keywords you put in. " \
                  "They will be used to train ML model in the backend.</p>"

    nlp = None
    matcher = None

    def __init__(self, description='', name=str(Step.global_id + 1)):
        super().__init__(name=name)
        self.sample_size_input = None
        self.percent_slider = None
        # save DOC_IDs that contain or not contain keywords filters (used in sampling strategy)
        self.samples = {"contain": [], "notcontain": []}
        self.box = None
        self.data = {'docs': [], 'annos': OrderedDict()}
        self.ready = False
        # reset, continue, addmore,
        self.move_next_option = ''

        self.un_reviewed = 0
        self.sampler = None
        self.max_threshold = ConfigReader.getValue("review/rb_model_threshold")
        pass

    def start(self):
        print('Please wait for reading data from db.', end='', flush=True)
        self.backgroundPrinting()
        self.init_real_time()
        clear_output(True)
        self.updateBox()
        display(self.box)
        pass

    def updateBox(self):
        total_contain = len(self.samples['contain'])
        total_not_contain = len(self.samples['notcontain'])
        desc = widgets.HTML(value='<h3>Start sampling for reviewing</h3>'
                                  '<p>The whole corpus has %s samples that contain at least one of the keywords, '
                                  'and %s don\'t contain.</p>' % (total_contain, total_not_contain))
        recommended_samples = int(total_contain / 2 + total_not_contain / 4)
        min_samples = 0
        if recommended_samples > 400:
            recommended_samples = 400
        self.sample_size_input = widgets.BoundedIntText(value=recommended_samples, min=min_samples,
                                                        max=total_contain + total_not_contain, step=1,
                                                        description='Total samples you want to sample:',
                                                        style=dict(description_width='initial'))
        desc2 = widgets.HTML(value='<h4>Percentage to Filter: </h4><p>Choose how many percent of the samples '
                                   'you want to contain the filter keywords. The rest percentage will be sampled '
                                   'randomly from the samples that do not have any filter keywords.</p>')
        self.percent_slider = widgets.IntSlider(
            value=60,
            min=0,
            max=100,
            step=5,
            description='',
            disabled=False,
            continuous_update=False,
            orientation='horizontal',
            readout=True,
            readout_format='d'
        )
        rows = [desc, self.sample_size_input]
        if len(self.data['annos']) > 0:
            side_note = widgets.HTML(
                value='<p>If you choose <span style="background-color:  #E8E8E8">AddExtraSampling</span>, then this '
                      'number will be the amount of extra samples that you want to add.')
            rows.append(side_note)
        rows += self.addSeparator(top='10px') + [desc2,
                                                 self.percent_slider] + self.addSeparator(
            top='10px') + [self.addPreviousNext(self.show_previous, self.show_next)]
        self.box = widgets.VBox(rows)
        pass

    def init_real_time(self):
        self.data['annos'].clear()
        self.data['docs'].clear()
        self.checkPreviousReviews()
        self.initSpacyNER()
        self.queryDocIds()
        pass

    def initSpacyNER(self):
        ReviewRBInit.nlp = spacy.blank('en')
        type_phrases = dict()
        for type_name, phrases in self.workflow.filters.items():
            type_phrases[type_name] = ([ReviewRBInit.nlp(phrase) for phrase in phrases])
            ReviewRBInit.matcher = PhraseMatcher(ReviewRBInit.nlp.vocab)
        for type_name, phrases in type_phrases.items():
            ReviewRBInit.matcher.add(type_name, None, *phrases)
        pass

    def checkPreviousReviews(self):
        """check if there is any samples have been reviewed before for the same task.
        If so, then let the user to choose how to proceed."""
        un_reviewed = 0
        with self.workflow.dao.create_session() as session:
            db_iter = session.query(Annotation, Document).join(Document, Document.DOC_ID == Annotation.DOC_ID).filter(
                Annotation.TASK_ID == self.workflow.task_id).distinct(Document.DOC_ID)
            for anno, doc in db_iter:
                self.data['annos'][anno.DOC_ID] = anno.clone()
                self.data['docs'].append(doc.clone())
                if anno.REVIEWED_TYPE is None or anno.REVIEWED_TYPE == "":
                    un_reviewed += 1

        if len(self.data['annos']) > 0:
            self.addCondition("ResetSampling", self.next_step, 'Remove previous reviewed data and restart sampling')
            self.addCondition("AddExtraSampling", self.next_step, 'Keep previous reviewed data and add extra samples')
            self.show_next = False
        else:
            self.show_next = True
        self.un_reviewed = un_reviewed
        if un_reviewed > 0:
            self.addCondition("ContinueReview", self.next_step,
                              'Don\'t sampling, just continue to finish reviewing previous sampled data')
        pass

    def queryDocIds(self):
        self.samples = {"contain": [], "notcontain": []}
        with self.workflow.dao.create_session() as session:
            doc_iter = session.query(Document).filter(Document.DATASET_ID == 'origin_doc')
            for doc in doc_iter:
                if len(ReviewRBInit.matcher(ReviewRBInit.nlp(doc.TEXT))) > 0:
                    self.samples['contain'].append(doc.DOC_ID)
                else:
                    self.samples['notcontain'].append(doc.DOC_ID)
                pass
        self.ready = True
        pass

    def backgroundPrinting(self):
        thread_gm = Thread(target=self.printWaiting)
        thread_gm.start()
        pass

    def printWaiting(self):
        while self.ready is False:
            print('.', end='', flush=True)
            sleep(1)
        pass

    def complete(self):
        clear_output(True)
        if len(self.data['annos']) > 0:
            self.continueReview()
        else:
            self.addExtra()
        if self.next_step is not None:
            logMsg((self, 'workflow complete'))
            if isinstance(self.next_step, Step):
                if self.workflow is not None:
                    self.workflow.updateStatus(self.next_step.pos_id)
                self.next_step.start()
            else:
                raise TypeError(
                    'Type error for ' + self.name + '\'s next_step. Only Step can be the next_step, where its next_step is ' + str(
                        type(self.next_step)))
        else:
            print("next step hasn't been set.")
        pass

    def navigate(self, b):
        clear_output(True)
        self.move_next_option = b.description[0].upper()
        if hasattr(b, 'linked_step'):
            self.updateData()
            b.linked_step.start()
        else:
            self.complete()
        pass

    def updateData(self, *args):
        """data related operations when click a button to move on to next step"""
        if self.move_next_option == "R":
            self.restSampling()
        elif self.move_next_option == "A":
            self.addExtra()
        else:
            self.continueReview()
        pass

    def addExtra(self):
        logMsg("add extra samples")
        self.getSampledDocs(set(self.data['annos'].keys()))
        pass

    def continueReview(self):
        logMsg("continue review")
        self.workflow.filter_percent = 0.01 * self.percent_slider.value
        # with self.workflow.dao.create_session() as session:
        #     # doc_iter = session.query(Annotation,Document).select_from(Document).join(Document.DOC_ID).filter(
        #     #     Annotation.TASK_ID == self.workflow.task_id)
        #     doc_iter = session.query(Document).filter(Document.DOC_ID == Annotation.DOC_ID).filter(
        #         Annotation.TASK_ID == self.workflow.task_id)
        #     for doc in doc_iter:
        #         docs.append(doc.clone())
        # self.data['docs'] = self.data['docs'] + docs
        # self.data = {'docs': docs, 'annos': self.previousSampled}
        self.workflow.sample_size = len(self.data['docs'])
        self.workflow.samples = self.data
        pass

    def restSampling(self):
        """discard previous sampling and reviewed data, start a new sampling"""
        logMsg('reset sampling')
        self.data['docs'].clear()
        self.data['annos'].clear()
        with self.workflow.dao.create_session() as session:
            anno_iter = session.query(Annotation).filter(Annotation.TASK_ID == self.workflow.task_id)
            for anno in anno_iter:
                session.delete(anno)
            session.commit()

        self.getSampledDocs()
        pass

    def getSampledDocs(self, exclusion_ids=set()):
        self.workflow.sample_size = self.sample_size_input.value
        self.workflow.filter_percent = 0.01 * self.percent_slider.value
        self.sampler = KeywordStratefiedSampler(filter_percent=self.workflow.filter_percent, dao=self.workflow.dao,
                                                stratefied_sets=self.samples, exclusions=exclusion_ids)
        # docs a list of Document object, if_contains a map with DOC_IDs as keys, 'contain' or 'notcontain' as the
        # values
        newly_sampled_docs = self.sampler.sampling(self.workflow.sample_size)
        self.data['docs'].extend(newly_sampled_docs)
        if len(self.data['docs']) > 0:
            self.workflow.sample_size = self.sampler.adjusted_sample_size
            self.workflow.filter_percent = self.sampler.adjusted_filter_percent
            self.workflow.samples = self.data
            with self.workflow.dao.create_session() as session:
                for doc in newly_sampled_docs:
                    anno = Annotation(TASK_ID=self.workflow.task_id,
                                      DOC_ID=doc.DOC_ID)
                    self.data['annos'][doc.DOC_ID] = anno.clone()
                    session.add(anno)
        if self.un_reviewed > 0:
            self.continueReview()
        pass
